{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14eec37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/satwiksahoo/Desktop/CodeBasics/machine learning/krish naik/NLP project/ATSresume/RESUME_ATS/research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%pwd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "028ba143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0182e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    \n",
    "    root_dir : Path\n",
    "    train_path : Path\n",
    "    test_path : Path\n",
    "    transformed_train_path : Path\n",
    "    transformed_test_path : Path\n",
    "    model_name  : Path\n",
    "    tokenizer_name : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0221dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ATS_RESUME.constants import *\n",
    "from src.ATS_RESUME.utils.common import read_yaml , create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "800dcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self , config_file_path = CONFIG_FILE_PATH , params_file_path = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifact_root])\n",
    "    \n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        \n",
    "        config = self.config.data_transformation\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir = config.root_dir ,\n",
    "            train_path = config.train_path ,\n",
    "            test_path = config.test_path ,\n",
    "            transformed_train_path = config.transformed_train_path ,\n",
    "            transformed_test_path = config.transformed_test_path , \n",
    "            model_name= config.model_name , \n",
    "            tokenizer_name=config.tokenizer_name\n",
    "\n",
    "            \n",
    "        )\n",
    "        \n",
    "        return data_transformation_config\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29f2f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer , pipeline\n",
    "\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self , config : DataTransformationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def preprocess_text(self , text):\n",
    "        tokens = []\n",
    "        text = re.sub(r'\\r\\n|\\n', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "        text = text.strip().lower()\n",
    "        return text\n",
    "    \n",
    "    def data_transformation_(self):\n",
    "        df_train  = pd.read_csv('./artifacts/data_ingestion/train.csv')\n",
    "        df_test  = pd.read_csv('./artifacts/data_ingestion/test.csv')\n",
    "        \n",
    "        df_train['label_encoding'] = df_train['label'].map({'No Fit' : 0  , 'Potential Fit' : 1 , 'Good Fit' : 2  } )\n",
    "        df_test['label_encoding'] = df_test['label'].map({'No Fit' : 0  , 'Potential Fit' : 1 , 'Good Fit' : 2  } )\n",
    "        \n",
    "        df_train['resume_text'] = df_train['resume_text'].apply(self.preprocess_text)\n",
    "        df_test['resume_text'] = df_test['resume_text'].apply(self.preprocess_text)\n",
    "        \n",
    "        \n",
    "        df_train['job_description_text'] = df_train['job_description_text'].apply(self.preprocess_text)\n",
    "        df_test['job_description_text'] = df_test['job_description_text'].apply(self.preprocess_text)\n",
    "        \n",
    "        num_labels = 3  # No Fit, Potential Fit, Good Fit\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",  num_labels=num_labels)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        \n",
    "        df_train['tokens'] = df_train.apply(lambda row: tokenizer(row['resume_text'] , row['job_description_text'] , padding = 'max_length' , \n",
    "                                                                  truncation = True  , max_length = 256)  ,axis = 1)\n",
    "        df_test['tokens'] = df_test.apply(lambda row: tokenizer(row['resume_text'] , row['job_description_text'] , padding = 'max_length' , \n",
    "                                                                  truncation = True  , max_length = 256)  ,axis = 1)\n",
    "        \n",
    "        tokens_df = pd.DataFrame(df_train['tokens'].tolist())\n",
    "        \n",
    "        df_train_expanded = pd.concat([tokens_df , df_train['label_encoding'] ] ,axis =1 )\n",
    "        df_test_expanded = pd.concat([pd.DataFrame(df_test['tokens'].tolist()) , df_test['label_encoding'] ] ,axis =1 )\n",
    "        \n",
    "        df_train_expanded.rename(columns={\"label_encoding\": \"labels\"}, inplace=True)\n",
    "        df_test_expanded.rename(columns={\"label_encoding\": \"labels\"}, inplace=True)\n",
    "        \n",
    "        \n",
    "        train_dataset = Dataset.from_pandas(df_train_expanded , preserve_index=False)\n",
    "        test_dataset = Dataset.from_pandas(df_test_expanded , preserve_index=False)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(self.config.transformed_train_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(self.config.transformed_test_path), exist_ok=True)\n",
    "        \n",
    "        train_dataset.save_to_disk(self.config.transformed_train_path)\n",
    "        test_dataset.save_to_disk(self.config.transformed_test_path)\n",
    "    \n",
    "    \n",
    "    def data_transformation(self):\n",
    "        \n",
    "        \n",
    "        df_train  = pd.read_csv('./artifacts/data_ingestion/train.csv')\n",
    "        df_test  = pd.read_csv('./artifacts/data_ingestion/test.csv')\n",
    "        label2score = {\n",
    "           \"No Fit\": 0.0,\n",
    "    \"Potential Fit\": 0.5,\n",
    "    \"Good Fit\": 1.0\n",
    "}       \n",
    "        \n",
    "        train_examples = [\n",
    "             InputExample(\n",
    "        texts=[row.resume_text, row.job_description_text],\n",
    "        label=label2score[row.label])\n",
    "             for _, row in df_train.iterrows()\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "        test_examples = [\n",
    "    InputExample(\n",
    "        texts=[row.resume_text, row.job_description_text],\n",
    "        label=label2score[row.label]\n",
    "    )\n",
    "    for _, row in df_test.iterrows()\n",
    "]\n",
    "\n",
    "\n",
    "        train_data = train_examples\n",
    "        val_data = test_examples\n",
    "        \n",
    "        os.makedirs(os.path.dirname(self.config.transformed_train_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(self.config.transformed_test_path), exist_ok=True)\n",
    "        \n",
    "        train_file = os.path.join(self.config.transformed_train_path, \"train.pkl\")\n",
    "        test_file = os.path.join(self.config.transformed_test_path, \"test.pkl\")\n",
    "        \n",
    "        # train_data.save_to_disk(self.config.transformed_train_path)\n",
    "        # val_data.save_to_disk(self.config.transformed_test_path)\n",
    "        \n",
    "        with open(train_file, \"wb\") as f:\n",
    "         pickle.dump(train_data, f)\n",
    "\n",
    "        with open(test_file, \"wb\") as f:\n",
    "         pickle.dump(val_data, f)\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c9c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_text</th>\n",
       "      <th>job_description_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SummaryHighly motivated Sales Associate with e...</td>\n",
       "      <td>Net2Source Inc. is an award-winning total work...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional SummaryCurrently working with Cat...</td>\n",
       "      <td>At Salas OBrien we tell our clients that were ...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SummaryI started my construction career in Jun...</td>\n",
       "      <td>Schweitzer Engineering Laboratories (SEL) Infr...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SummaryCertified Electrical Foremanwith thirte...</td>\n",
       "      <td>Mizick Miller &amp; Company, Inc. is looking for a...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SummaryWith extensive experience in business/r...</td>\n",
       "      <td>Life at Capgemini\\nCapgemini supports all aspe...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         resume_text  \\\n",
       "0  SummaryHighly motivated Sales Associate with e...   \n",
       "1  Professional SummaryCurrently working with Cat...   \n",
       "2  SummaryI started my construction career in Jun...   \n",
       "3  SummaryCertified Electrical Foremanwith thirte...   \n",
       "4  SummaryWith extensive experience in business/r...   \n",
       "\n",
       "                                job_description_text   label  \n",
       "0  Net2Source Inc. is an award-winning total work...  No Fit  \n",
       "1  At Salas OBrien we tell our clients that were ...  No Fit  \n",
       "2  Schweitzer Engineering Laboratories (SEL) Infr...  No Fit  \n",
       "3  Mizick Miller & Company, Inc. is looking for a...  No Fit  \n",
       "4  Life at Capgemini\\nCapgemini supports all aspe...  No Fit  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_train  = pd.read_csv('./artifacts/data_ingestion/train.csv')\n",
    "\n",
    "\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49c19f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-19 23:48:25,354: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2025-08-19 23:48:25,357: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-08-19 23:48:25,358: INFO: common: created directory at: artifacts]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "data_transformation_config = config.get_data_transformation_config()\n",
    "data_transformation = DataTransformation(config = data_transformation_config)\n",
    "data_transformation.data_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3f5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
